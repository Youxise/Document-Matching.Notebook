{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddb2644-442a-44d0-ad1e-c9e8e4706f8a",
   "metadata": {},
   "source": [
    "Exécution du TP1 afin d'avoir les phrases et les tokens du corpus Chirac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdb413f-5feb-4c8b-b769-760a6a767108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Corpus Obama ------------\n",
      "\n",
      "Le nombre de phrases est : 84\n",
      "Le nombre de tokens est : 658\n",
      "---------- Corpus Chirac ------------\n",
      "\n",
      "Le nombre de phrases est : 37\n",
      "Le nombre de tokens est : 293\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "%run TP1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9de40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4d9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    return re.split(r'(?<=[.!?])\\s+', text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760c7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(sentences):\n",
    "    unique_tokens = set()\n",
    "    for sentence in sentences:\n",
    "        tokens = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
    "        unique_tokens.update(tokens)\n",
    "    return sorted(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2db8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_matrix(sentences, unique_tokens, matrix_type, normalization_type):\n",
    "\n",
    "    freq_matrix = []\n",
    "    if matrix_type == 'Binary':\n",
    "        for sentence in sentences:\n",
    "\n",
    "            tokens = [word.lower() for word in sentence.split() if word.isalnum()]\n",
    "            \n",
    "            matrix_row = [1 if token in tokens else 0 for token in unique_tokens]\n",
    "            freq_matrix.append(matrix_row)\n",
    "    else: # Occurence\n",
    "        for sentence in sentences:\n",
    "\n",
    "            tokens = [word.lower() for word in sentence.split() if word.isalnum()]\n",
    "\n",
    "            matrix_row = [tokens.count(token) for token in unique_tokens]\n",
    "            freq_matrix.append(matrix_row)\n",
    "\n",
    "    # Appliquer la normalisation\n",
    "    if normalization_type == \"Probability\":\n",
    "        for row in freq_matrix:\n",
    "            row_sum = sum(row)\n",
    "            for i in range(len(row)):\n",
    "                row[i] = row[i] / row_sum if row_sum != 0 else 0\n",
    "    elif normalization_type == \"L2\":\n",
    "        for row in freq_matrix:\n",
    "            row_sum = sum(x**2 for x in row) ** 0.5\n",
    "            for i in range(len(row)):\n",
    "                row[i] = row[i] / row_sum if row_sum != 0 else 0\n",
    "\n",
    "    return freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915dfbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSimilarityMatrix(sentences, bow_matrix, distance):\n",
    "    \n",
    "    distance_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                distance_matrix[i][j] = distance(bow_matrix[i], bow_matrix[j])\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "documents = [\"the cat sat on the mat\",    \"the dog sat on the log\",    \"cats and dogs are great pets\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_bin, distance_euclidean)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ, distance_euclidean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1af5b-5c69-404f-8489-dd13a4a5fe95",
   "metadata": {},
   "source": [
    "# Descripteurs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f96a00-3418-493b-bf4c-b1971d23de6b",
   "metadata": {},
   "source": [
    "1. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1a73341-2e9e-4a42-850c-2bd7c0eef2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_bin(document, vocabulaire):\n",
    "    bow_bin = [1 if token in document.split() else 0 for token in vocabulaire]\n",
    "    return bow_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f959cadf-59f3-416d-baad-6f909438041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_occ(document, vocabulaire):\n",
    "    bow_occ = [document.split().count(token) for token in vocabulaire]\n",
    "    return bow_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc00cbba-aad7-47b5-a881-f1533d204cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_N1(bow_occ):\n",
    "    somme = sum(bow_occ)\n",
    "    bow = [i/somme for i in bow_occ]\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24692589-fbda-4a23-9967-ba8399b27da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_N2(bow_occ):\n",
    "    somme = 0\n",
    "    for elt in bow_occ:\n",
    "        somme += elt**2\n",
    "    bow = [i/math.sqrt(somme) for i in bow_occ]\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50952f44-05db-4a83-bf91-2049cbe2e739",
   "metadata": {},
   "source": [
    "2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb0c1aef-f399-4a67-8be1-74bb0429b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_bin(document, vocabulaire):\n",
    "    return [1 if token in document.split() else 0 for token in vocabulaire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34f7fc52-bf9c-4e44-9d00-8ec14c5c7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_occ(document, vocabulaire):\n",
    "    return [document.split().count(token) for token in vocabulaire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b7addf4-233d-496f-b039-cbc8f100f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_occ_N(document, vocabulaire):\n",
    "    \"\"\"Calcul du TF normalisé (occurrences / nombre de mots) pour chaque terme du vocabulaire dans le document.\"\"\"\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    return [words.count(token) / total_words if total_words > 0 else 0 for token in vocabulaire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "324dd2a6-0b9e-4877-b694-3114fb046af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(documents, vocabulaire):\n",
    "    \"\"\"Calcul de l'IDF pour chaque terme du vocabulaire.\"\"\"\n",
    "    N = len(documents)  # Nombre total de documents\n",
    "    idf_list = []\n",
    "\n",
    "    for token in vocabulaire:\n",
    "        # Compter combien de documents contiennent le terme\n",
    "        df = sum(1 for doc in documents if token in doc.split())\n",
    "        if df != 0:\n",
    "            idf = math.log(N / df)  # Ajout de 1 pour éviter division par zéro\n",
    "        else:\n",
    "            idf = 0\n",
    "        idf_list.append(idf)\n",
    "    \n",
    "    return idf_list\n",
    "\n",
    "def compute_tf_idf(documents, vocabulaire, tf_function):\n",
    "    \"\"\"Construction de la matrice TF-IDF.\"\"\"\n",
    "    # calcul de l'IDF pour le vocabulaire\n",
    "    idf_list = compute_idf(documents, vocabulaire)\n",
    "    \n",
    "    # construction de la matrice TF-IDF pour chaque document\n",
    "    tf_idf_matrix = []\n",
    "    for document in documents:\n",
    "        # calcul du TF \n",
    "        tf_vector = tf_function(document, vocabulaire)\n",
    "        \n",
    "        # calcul de TF * IDF\n",
    "        tf_idf_vector = [tf * idf for tf, idf in zip(tf_vector, idf_list)]\n",
    "        tf_idf_matrix.append(tf_idf_vector)\n",
    "    \n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae63bd3-3768-4020-9595-fd152e12ca43",
   "metadata": {},
   "source": [
    "Distances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71712283-37d6-4436-b020-cba7bc36c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_euclidean(vect1, vect2):\n",
    "    s = 0\n",
    "    for i in range(len(vect1)):\n",
    "        s += math.pow(vect1[i] - vect2[i], 2)\n",
    "    \n",
    "    return math.sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867768e5-4b58-468d-ada3-ad183bc0ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_manhattan(vect1, vect2):\n",
    "    s = 0\n",
    "    for i in range(len(vect1)):\n",
    "        s += abs(vect1[i] - vect2[i])\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fb35a7-ad2e-4fb6-bade-525f5a7ed4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_cosinus(vect1, vect2):\n",
    "    somme_norm1 = 0\n",
    "    somme_norm2 = 0\n",
    "    produit_scalaire = 0\n",
    "    for i in range(len(vect1)):\n",
    "        somme_norm1 += vect1[i]**2\n",
    "        somme_norm2 += vect2[i]**2\n",
    "        produit_scalaire += vect1[i]*vect2[i]\n",
    "\n",
    "    return (1 - (produit_scalaire/(math.sqrt(somme_norm1)*math.sqrt(somme_norm2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8d699e-feec-409b-a9da-89593b96e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_jaccard(vect1, vect2):\n",
    "    somme_union = 0\n",
    "    somme_intersec = 0\n",
    "    for i in range(len(vect1)):\n",
    "        if vect1[i] != vect2[i]:\n",
    "            somme_union += 1\n",
    "        elif vect1[i] != 0 or vect2[i] != 0: # s'assurer que les deux mots se trouvent au moins une fois dans les documents\n",
    "            somme_intersec += 1\n",
    "            \n",
    "    return (1 - (somme_intersec/somme_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c4c1ca-5aac-4183-9127-a50d20e6d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_hamming(vect1, vect2):\n",
    "    somme_diff = 0\n",
    "    for i in range(len(vect1)):\n",
    "        if vect1[i] != vect2[i]:\n",
    "            somme_diff += 1\n",
    "            \n",
    "    return somme_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a58568-93da-4f16-95b4-e56f2a74b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_bray_curtis(vect1, vect2):\n",
    "    somme_abs = 0\n",
    "    somme = 0\n",
    "    for i in range(len(vect1)):\n",
    "        somme_abs += abs(vect1[i] - vect2[i])\n",
    "        somme += vect1[i] + vect2[i]\n",
    "\n",
    "    if somme != 0:\n",
    "        return somme_abs / somme\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbafd728-6def-4422-a4a3-49d32e52e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_kullback_leibler(vect1, vect2):\n",
    "    somme = 0\n",
    "    for i in range(len(vect1)):\n",
    "        if vect1[i] > 0 and vect2[i] > 0:\n",
    "            somme += vect1[i] * math.log(vect1[i]/vect2[i])\n",
    "\n",
    "    return somme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969df1c-173f-4062-a290-0fe127c8a82e",
   "metadata": {},
   "source": [
    "Création de la matrice BoW et la matrice de similarité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45a490f5-f8c8-4ea4-b204-3df293e3f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # pour l'affichage seulement\n",
    "\n",
    "def createBoWMatrix(function1, sentences, tokens, function2):\n",
    "\n",
    "    #matrix = []\n",
    "    #for sentence in sentences:\n",
    "    #    if function1 and function2:\n",
    "    #        matrix.append(function2(function1(sentence, tokens)))\n",
    "    #    elif function1:\n",
    "    #        matrix.append(function1(sentence, tokens))\n",
    "    #    else:\n",
    "    #        matrix.append(bow_occ(sentence, tokens)\n",
    "        \n",
    "    matrix = [function2(function1(sentence, tokens)) if function1 and function2\n",
    "            else function1(sentence, tokens) if function1\n",
    "            else bow_occ(sentence, tokens)\n",
    "            for sentence in sentences]\n",
    "    \n",
    "    print(\"bow_matrix:\\n\",np.array(matrix), \"\\n\")\n",
    "\n",
    "    #print(pd.DataFrame(matrix, columns=tokens, index=[f\"Phrase_{i+1}\" for i in range(len(sentences))]))\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def createSimilarityMatrix(sentences, bow_matrix, distance):\n",
    "    \n",
    "    distance_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                distance_matrix[i][j] = distance(bow_matrix[i], bow_matrix[j])\n",
    "\n",
    "    return distance_matrix\n",
    "                \n",
    "    #return euclidean_matrix, manhattan_matrix, cosinus_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb96f7-8a9b-4e7d-8551-aef4d0666eb6",
   "metadata": {},
   "source": [
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dc2f5ae-705b-432b-964d-dbe4a8c6dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice TF-IDF avec TF binaire:\n",
      "Document 1: [0.4054651081081644, 0.0, 0.0, 1.0986122886681098, 0.0, 0.0, 0.4054651081081644, 1.0986122886681098, 0.4054651081081644, 0.0, 0.0, 0.0, 0.0]\n",
      "Document 2: [0.4054651081081644, 0.0, 0.0, 0.0, 0.0, 1.0986122886681098, 0.4054651081081644, 0.0, 0.4054651081081644, 0.0, 0.0, 0.0, 1.0986122886681098]\n",
      "Document 3: [0.0, 1.0986122886681098, 1.0986122886681098, 0.0, 1.0986122886681098, 0.0, 0.0, 0.0, 0.0, 1.0986122886681098, 1.0986122886681098, 1.0986122886681098, 0.0]\n",
      "\n",
      "Matrice TF-IDF avec TF par occurrences:\n",
      "Document 1: [0.4054651081081644, 0.0, 0.0, 1.0986122886681098, 0.0, 0.0, 0.8109302162163288, 1.0986122886681098, 0.4054651081081644, 0.0, 0.0, 0.0, 0.0]\n",
      "Document 2: [0.4054651081081644, 0.0, 0.0, 0.0, 0.0, 1.0986122886681098, 0.8109302162163288, 0.0, 0.4054651081081644, 0.0, 0.0, 0.0, 1.0986122886681098]\n",
      "Document 3: [0.0, 1.0986122886681098, 1.0986122886681098, 0.0, 1.0986122886681098, 0.0, 0.0, 0.0, 0.0, 1.0986122886681098, 1.0986122886681098, 1.0986122886681098, 0.0]\n",
      "\n",
      "Matrice TF-IDF avec TF par occurrences normalisees:\n",
      "Document 1: [0.06757751801802739, 0.0, 0.0, 0.1831020481113516, 0.0, 0.0, 0.13515503603605478, 0.1831020481113516, 0.06757751801802739, 0.0, 0.0, 0.0, 0.0]\n",
      "Document 2: [0.06757751801802739, 0.0, 0.0, 0.0, 0.0, 0.1831020481113516, 0.13515503603605478, 0.0, 0.06757751801802739, 0.0, 0.0, 0.0, 0.1831020481113516]\n",
      "Document 3: [0.0, 0.1831020481113516, 0.1831020481113516, 0.0, 0.1831020481113516, 0.0, 0.0, 0.0, 0.0, 0.1831020481113516, 0.1831020481113516, 0.1831020481113516, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Exemple\n",
    "documents = [\"the cat sat on the mat\",    \"the dog sat on the log\",    \"cats and dogs are great pets\"]\n",
    "\n",
    "vocabulaire = list(set(\" \".join(documents).split()))\n",
    "\n",
    "# TF-bin\n",
    "tf_idf_bin = compute_tf_idf(documents, vocabulaire, TF_bin)\n",
    "print(\"Matrice TF-IDF avec TF binaire:\")\n",
    "for i, vec in enumerate(tf_idf_bin):\n",
    "    print(f\"Document {i+1}: {vec}\")\n",
    "\n",
    "# TF-occ\n",
    "tf_idf_occ = compute_tf_idf(documents, vocabulaire, TF_occ)\n",
    "print(\"\\nMatrice TF-IDF avec TF par occurrences:\")\n",
    "for i, vec in enumerate(tf_idf_occ):\n",
    "    print(f\"Document {i+1}: {vec}\")\n",
    "\n",
    "# TF-occ-N\n",
    "tf_idf_occ_N = compute_tf_idf(documents, vocabulaire, TF_occ_N)\n",
    "print(\"\\nMatrice TF-IDF avec TF par occurrences normalisees:\")\n",
    "for i, vec in enumerate(tf_idf_occ_N):\n",
    "    print(f\"Document {i+1}: {vec}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63b03bf5-fc6b-4f97-b8bf-1d5ed22d4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         2.19722458 3.18571774]\n",
      " [2.19722458 0.         3.18571774]\n",
      " [3.18571774 3.18571774 0.        ]]\n",
      "[[0.         2.19722458 3.26220836]\n",
      " [2.19722458 0.         3.26220836]\n",
      " [3.26220836 3.26220836 0.        ]]\n",
      "[[0.         0.3662041  0.54370139]\n",
      " [0.3662041  0.         0.54370139]\n",
      " [0.54370139 0.54370139 0.        ]]\n",
      "\n",
      "------------------------------------------------\n",
      "[[ 0.          4.39444915 10.00529363]\n",
      " [ 4.39444915  0.         10.00529363]\n",
      " [10.00529363 10.00529363  0.        ]]\n",
      "[[ 0.          4.39444915 10.41075874]\n",
      " [ 4.39444915  0.         10.41075874]\n",
      " [10.41075874 10.41075874  0.        ]]\n",
      "[[0.         0.73240819 1.73512646]\n",
      " [0.73240819 0.         1.73512646]\n",
      " [1.73512646 1.73512646 0.        ]]\n",
      "\n",
      "------------------------------------------------\n",
      "[[0.        0.8303446 1.       ]\n",
      " [0.8303446 0.        1.       ]\n",
      " [1.        1.        0.       ]]\n",
      "[[0.         0.70990532 1.        ]\n",
      " [0.70990532 0.         1.        ]\n",
      " [1.         1.         0.        ]]\n",
      "[[0.         0.70990532 1.        ]\n",
      " [0.70990532 0.         1.        ]\n",
      " [1.         1.         0.        ]]\n",
      "\n",
      "------------------------------------------------\n",
      "[[0.        0.6436641 1.       ]\n",
      " [0.6436641 0.        1.       ]\n",
      " [1.        1.        0.       ]]\n",
      "[[0.         0.57532749 1.        ]\n",
      " [0.57532749 0.         1.        ]\n",
      " [1.         1.         0.        ]]\n",
      "[[0.         0.57532749 1.        ]\n",
      " [0.57532749 0.         1.        ]\n",
      " [1.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_bin, distance_euclidean)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ, distance_euclidean)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ_N, distance_euclidean)))\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_bin, distance_manhattan)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ, distance_manhattan)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ_N, distance_manhattan)))\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_bin, distance_cosinus)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ, distance_cosinus)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ_N, distance_cosinus)))\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_bin, distance_bray_curtis)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ, distance_bray_curtis)))\n",
    "print(np.array(createSimilarityMatrix(documents[:3], tf_idf_occ_N, distance_bray_curtis)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13bc91a-8fd5-4c48-87ae-d26ef4cf309e",
   "metadata": {},
   "source": [
    "------------------------------------------------------- (bow part) ------------------------------------------------------\n",
    "# deroulement :\n",
    "- create bow matrix (avec les fonctions, tokens, phrases)\n",
    "- create similarity matrix (avec la fonction, bow, phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf633410-bcd2-481d-ae52-da89c9e61698",
   "metadata": {},
   "source": [
    "Exemple (Corpus chat-chien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "99d26357-6156-4eef-ad67-f358462dc706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination \", \"mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation \", 'mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république ', 'je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste ', \"je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel \", \"je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir \", \"j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change \", \"tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français \", \"ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe \", \"votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain \", \"ce choix m'oblige comme il oblige chaque responsable de notre pays ce choix m'oblige comme il oblige chaque responsable de notre pays \", \"chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel \", \"votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques \", \"la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination \", 'président de tous les français, je veux y répondre dans un esprit de rassemblement président de tous les français, je veux y répondre dans un esprit de rassemblement ', 'je veux mettre la république au service de tous je veux mettre la république au service de tous ', \"je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous \", \"la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité \", \"faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir \", \"la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts \", \"l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous \", \"la fraternité, c'est sauvegarder les retraites la fraternité, c'est sauvegarder les retraites \", \"c'est aider les familles à jouer pleinement leur rôle c'est aider les familles à jouer pleinement leur rôle \", \"c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte \", \"la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité \", \"dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés \", \"son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi \", \"c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie \", \"cette exigence s'impose à chacun d'entre nous cette exigence s'impose à chacun d'entre nous \", 'elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous ', \"mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat \", \"les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français \", 'ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ', \"chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france \", \"il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir \", 'vive la république vive la république ', 'vive la france vive la france ']\n",
      "[\"la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination \", \"mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation \", 'mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république ', 'je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste je salue la france, fidèle à elle-même, fidèle à ses grands idéaux, fidèle à sa vocation universelle et humaniste ', \"je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel je salue la france qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel \", \"je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir je salue les françaises et les français épris de solidarité et de liberté, soucieux de s'ouvrir à l'europe et au monde, tournés vers l'avenir \", \"j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change j'ai entendu et compris votre appel pour que la république vive, pour que la nation se rassemble, pour que la politique change \", \"tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français tout dans l'action qui sera conduite, devra répondre à cet appel et s'inspirer d'une exigence de service et d'écoute pour chaque française et chaque français \", \"ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe ce soir, je veux vous dire aussi mon émotion et le sentiment que j'ai de la responsabilité qui m'incombe \", \"votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte républicain \", \"ce choix m'oblige comme il oblige chaque responsable de notre pays ce choix m'oblige comme il oblige chaque responsable de notre pays ce choix m'oblige comme il oblige chaque responsable de notre pays ce choix m'oblige comme il oblige chaque responsable de notre pays \", \"chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel chacun mesure bien, à l'aune de notre histoire, la force de ce moment exceptionnel \", \"votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques votre décision, vous l'avez prise en conscience, en dépassant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delà même de vos préférences personnelles ou politiques \", \"la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination \", 'président de tous les français, je veux y répondre dans un esprit de rassemblement président de tous les français, je veux y répondre dans un esprit de rassemblement président de tous les français, je veux y répondre dans un esprit de rassemblement président de tous les français, je veux y répondre dans un esprit de rassemblement ', 'je veux mettre la république au service de tous je veux mettre la république au service de tous je veux mettre la république au service de tous je veux mettre la république au service de tous ', \"je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous je veux que les valeurs de liberté, d'égalité et de fraternité reprennent toute leur place dans la vie de chacune et de chacun d'entre nous \", \"la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité la liberté, c'est la sécurité, la lutte contre la violence, le refus de l'impunité \", \"faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir faire reculer l'insécurité est la première priorité de l'etat pour les temps à venir \", \"la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts la liberté, c'est aussi la reconnaissance du travail et du mérite, la réduction des charges et des impôts \", \"l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous l'égalité, c'est le refus de toute discrimination, ce sont les mêmes droits et les mêmes devoirs pour tous \", \"la fraternité, c'est sauvegarder les retraites la fraternité, c'est sauvegarder les retraites la fraternité, c'est sauvegarder les retraites la fraternité, c'est sauvegarder les retraites \", \"c'est aider les familles à jouer pleinement leur rôle c'est aider les familles à jouer pleinement leur rôle c'est aider les familles à jouer pleinement leur rôle c'est aider les familles à jouer pleinement leur rôle \", \"c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte c'est faire en sorte que personne n'éprouve plus le sentiment d'être laissé pour compte \", \"la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité la france, forte de sa cohésion sociale et de son dynamisme économique, portera en europe et dans le monde l'ambition de la paix, des libertés et de la solidarité \", \"dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tâche de répondre à vos préoccupations et d'apporter des solutions à des problèmes trop longtemps négligés \", \"son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi son premier devoir sera de rétablir l'autorité de l'etat pour répondre à l'exigence de sécurité, et de mettre la france sur un nouveau chemin de croissance et d'emploi \", \"c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie c'est par une action forte et déterminée, c'est par la solidarité de la nation, c'est par l'efficacité des résultats obtenus, que nous pourrons lutter contre l'intolérance, faire reculer l'extrémisme, garantir la vitalité de notre démocratie \", \"cette exigence s'impose à chacun d'entre nous cette exigence s'impose à chacun d'entre nous cette exigence s'impose à chacun d'entre nous cette exigence s'impose à chacun d'entre nous \", 'elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous elle impliquera, au cours des prochaines années, vigilance et mobilisation de la part de tous ', \"mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat mes chers compatriotes,\\nle mandat que vous m'avez confié, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unité de la république, la cohésion de la nation et le respect de l'autorité de l'etat \", \"les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français les jours que nous venons de vivre ont ranimé la vigueur nationale, la vigueur de l'idéal démocratique français \", 'ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ils ont exprimé une autre idée de la politique, une autre idée de la citoyenneté ', \"chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france chacune et chacun d'entre vous, conscient de ses responsabilités, par un choix de liberté, a contribué, ce soir, à forger le destin de la france \", \"il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir il y a là un espoir qui ne demande qu'à grandir, un espoir que je veux servir \", 'vive la république vive la république vive la république vive la république ', 'vive la france vive la france vive la france vive la france ']\n"
     ]
    }
   ],
   "source": [
    "# mettre en commentaire les deux lignes suivantes pour executer le corpus de Chirac\n",
    "#sentences = [\"the cat sat on the mat\",    \"the dog sat on the log\",    \"cats and dogs are great pets\"] ###\n",
    "#tokens = list(set(\" \".join(sentences).split())) ###\n",
    "\n",
    "\n",
    "sentences_prime = []\n",
    "sentences_deux_primes = []\n",
    "for sent in sentences:\n",
    "    sentences_prime.append((sent + \" \")*2)\n",
    "    sentences_deux_primes.append((sent + \" \")*4)\n",
    "\n",
    "print(sentences_prime)\n",
    "print(sentences_deux_primes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf61fb9-cc87-492e-80f6-a945db00fd3a",
   "metadata": {},
   "source": [
    "** test **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b688ebf-60bc-48df-89dd-c091202487f9",
   "metadata": {},
   "source": [
    "1. Résultats des phrases (normales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593f906-023e-4f1b-910f-13b76a536a14",
   "metadata": {},
   "source": [
    "- Distance Curtis :\n",
    "  Chats & Chiens : bons resultats\n",
    "  Chirac :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fde65442-0230-4723-926d-43c05fc44ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases :\n",
      " [\"la confiance que vous venez de me témoigner, je veux y répondre en m'engageant dans l'action avec détermination\", \"mes chers compatriotes de métropole, d'outre-mer et de l'étranger,\\nnous venons de vivre un temps de grave inquiétude pour la nation\", 'mais ce soir, dans un grand élan la france a réaffirmé son attachement aux valeurs de la république']\n",
      "\n",
      "---------------------------- Bin Jaccard ----------------------------\n",
      "\n",
      "bow_matrix:\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0]] \n",
      "\n",
      "[[0.         0.86666667 0.80645161]\n",
      " [0.86666667 0.         0.80645161]\n",
      " [0.80645161 0.80645161 0.        ]]\n",
      "\n",
      "---------------------------- Bin Hamming ----------------------------\n",
      "\n",
      "bow_matrix:\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0]] \n",
      "\n",
      "[[0.         0.87878788 0.8125    ]\n",
      " [0.87878788 0.         0.82857143]\n",
      " [0.8125     0.82857143 0.        ]]\n",
      "\n",
      "---------------------------- N1 ----------------------------\n",
      "\n",
      "bow_matrix:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06666667 0.\n",
      "  0.         0.06666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06666667 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06666667 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06666667 0.         0.         0.\n",
      "  0.         0.         0.         0.06666667 0.         0.\n",
      "  0.         0.         0.         0.06666667 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06666667 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06666667 0.         0.         0.         0.\n",
      "  0.06666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06666667 0.         0.         0.         0.         0.\n",
      "  0.06666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05555556 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22222222 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05555556 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05555556 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05555556 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05555556 0.         0.         0.\n",
      "  0.05555556 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05555556 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05555556 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05555556 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05555556 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05555556\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05555556 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05555556\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05555556 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05882353 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11764706 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05882353 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05882353 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05882353 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05882353 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05882353 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05882353 0.        ]] \n",
      "\n",
      "[[0.         0.87777778 0.81568627]\n",
      " [0.87777778 0.         0.83006536]\n",
      " [0.81568627 0.83006536 0.        ]]\n",
      "\n",
      "---------------------------- N2 ----------------------------\n",
      "\n",
      "bow_matrix:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25819889 0.\n",
      "  0.         0.25819889 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25819889 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25819889 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25819889 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25819889 0.         0.         0.\n",
      "  0.         0.         0.         0.25819889 0.         0.\n",
      "  0.         0.         0.         0.25819889 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25819889 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25819889 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25819889 0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18257419 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.73029674 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18257419 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18257419 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18257419 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18257419 0.         0.         0.\n",
      "  0.18257419 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18257419 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18257419 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18257419 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18257419 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18257419\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18257419 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18257419\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18257419 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22941573 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22941573 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.45883147 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22941573 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22941573 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22941573\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22941573\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22941573 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22941573 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22941573 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22941573 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22941573\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22941573 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22941573 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22941573 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22941573 0.        ]] \n",
      "\n",
      "[[0.         0.87686731 0.81550864]\n",
      " [0.87686731 0.         0.83453082]\n",
      " [0.81550864 0.83453082 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Phrases :\\n\", sentences[:3])\n",
    "\n",
    "print(\"\\n---------------------------- Bin Jaccard ----------------------------\\n\")\n",
    "print(np.array(createSimilarityMatrix(sentences[:3], createBoWMatrix(bow_bin, sentences[:3], tokens, None), distance_bray_curtis)))\n",
    "\n",
    "print(\"\\n---------------------------- Bin Hamming ----------------------------\\n\")\n",
    "print(np.array(createSimilarityMatrix(sentences[:3], createBoWMatrix(bow_occ, sentences[:3], tokens, None), distance_bray_curtis)))\n",
    "\n",
    "print(\"\\n---------------------------- N1 ----------------------------\\n\")\n",
    "print(np.array(createSimilarityMatrix(sentences[:3], createBoWMatrix(bow_occ, sentences[:3], tokens, bow_N1), distance_bray_curtis)))\n",
    "\n",
    "print(\"\\n---------------------------- N2 ----------------------------\\n\")\n",
    "print(np.array(createSimilarityMatrix(sentences[:3], createBoWMatrix(bow_occ, sentences[:3], tokens, bow_N2), distance_bray_curtis)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c94d26-a2e0-4356-8221-1efd42a7c0ac",
   "metadata": {},
   "source": [
    "2. Résultats des phrases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "129b693f-bcb0-495e-bcfe-fe95f2573291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases' :\n",
      " ['the cat sat on the mat the cat sat on the mat ', 'the dog sat on the log the dog sat on the log ', 'cats and dogs are great pets cats and dogs are great pets ']\n",
      "\n",
      "---------------------------- Bin ----------------------------\n",
      "\n",
      "bow_matrix:\n",
      " [[1 0 1 1 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 1 1 0 0 1 1 1 0 0 0]\n",
      " [0 1 0 0 0 1 1 0 0 0 1 1 1]] \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "createSimilarityMatrix() missing 1 required positional argument: 'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhrases\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sentences_prime[:\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------------------- Bin ----------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcreateSimilarityMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_prime\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreateBoWMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbow_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences_prime\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------------------- Occ ----------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m createSimilarityMatrix(sentences_prime[:\u001b[38;5;241m3\u001b[39m], createBoWMatrix(bow_occ, sentences_prime[:\u001b[38;5;241m3\u001b[39m], tokens, \u001b[38;5;28;01mNone\u001b[39;00m)) \n",
      "\u001b[1;31mTypeError\u001b[0m: createSimilarityMatrix() missing 1 required positional argument: 'distance'"
     ]
    }
   ],
   "source": [
    "print(\"Phrases' :\\n\", sentences_prime[:3])\n",
    "\n",
    "print(\"\\n---------------------------- Bin ----------------------------\\n\")\n",
    "createSimilarityMatrix(sentences_prime[:3], createBoWMatrix(bow_bin, sentences_prime[:3], tokens, None)) \n",
    "\n",
    "print(\"\\n---------------------------- Occ ----------------------------\\n\")\n",
    "createSimilarityMatrix(sentences_prime[:3], createBoWMatrix(bow_occ, sentences_prime[:3], tokens, None)) \n",
    "\n",
    "print(\"\\n---------------------------- N1 ----------------------------\\n\")\n",
    "\n",
    "createSimilarityMatrix(sentences_prime[:3], createBoWMatrix(bow_occ, sentences_prime[:3], tokens, bow_N1)) # N1\n",
    "\n",
    "print(\"\\n---------------------------- N2 ----------------------------\\n\")\n",
    "\n",
    "createSimilarityMatrix(sentences_prime[:3], createBoWMatrix(bow_occ, sentences_prime[:3], tokens, bow_N2)) # N2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205e34f-6b33-4b9f-8437-babeeaf8ad06",
   "metadata": {},
   "source": [
    "3. Résultats des phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd5f21e8-fdda-471b-a91c-aca1b2e76f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases'' :\n",
      " ['the cat sat on the mat the cat sat on the mat the cat sat on the mat the cat sat on the mat ', 'the dog sat on the log the dog sat on the log the dog sat on the log the dog sat on the log ', 'cats and dogs are great pets cats and dogs are great pets cats and dogs are great pets cats and dogs are great pets ']\n",
      "\n",
      "---------------------------- Bin ----------------------------\n",
      "\n",
      "\n",
      "Matrice de similarité avec la distance euclidéene:\n",
      "[[0.         2.         3.31662479]\n",
      " [2.         0.         3.31662479]\n",
      " [3.31662479 3.31662479 0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance manhattan:\n",
      "[[ 0  4 11]\n",
      " [ 4  0 11]\n",
      " [11 11  0]]\n",
      "\n",
      "Matrice de similarité avec la distance cosinus:\n",
      "[[0.  0.4 1. ]\n",
      " [0.4 0.  1. ]\n",
      " [1.  1.  0. ]]\n",
      "\n",
      "---------------------------- Occ ----------------------------\n",
      "\n",
      "\n",
      "Matrice de similarité avec la distance euclidéene:\n",
      "[[ 0.          8.         14.96662955]\n",
      " [ 8.          0.         14.96662955]\n",
      " [14.96662955 14.96662955  0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance manhattan:\n",
      "[[ 0 16 48]\n",
      " [16  0 48]\n",
      " [48 48  0]]\n",
      "\n",
      "Matrice de similarité avec la distance cosinus:\n",
      "[[0.   0.25 1.  ]\n",
      " [0.25 0.   1.  ]\n",
      " [1.   1.   0.  ]]\n",
      "\n",
      "---------------------------- N1 ----------------------------\n",
      "\n",
      "\n",
      "Matrice de similarité avec la distance euclidéene:\n",
      "[[0.         0.33333333 0.62360956]\n",
      " [0.33333333 0.         0.62360956]\n",
      " [0.62360956 0.62360956 0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance manhattan:\n",
      "[[0.         0.66666667 2.        ]\n",
      " [0.66666667 0.         2.        ]\n",
      " [2.         2.         0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance cosinus:\n",
      "[[0.   0.25 1.  ]\n",
      " [0.25 0.   1.  ]\n",
      " [1.   1.   0.  ]]\n",
      "\n",
      "---------------------------- N2 ----------------------------\n",
      "\n",
      "\n",
      "Matrice de similarité avec la distance euclidéene:\n",
      "[[0.         0.70710678 1.41421356]\n",
      " [0.70710678 0.         1.41421356]\n",
      " [1.41421356 1.41421356 0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance manhattan:\n",
      "[[0.         1.41421356 4.57081009]\n",
      " [1.41421356 0.         4.57081009]\n",
      " [4.57081009 4.57081009 0.        ]]\n",
      "\n",
      "Matrice de similarité avec la distance cosinus:\n",
      "[[0.   0.25 1.  ]\n",
      " [0.25 0.   1.  ]\n",
      " [1.   1.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Phrases'' :\\n\", sentences_deux_primes[:3])\n",
    "\n",
    "print(\"\\n---------------------------- Bin ----------------------------\\n\")\n",
    "createSimilarityMatrix(sentences_deux_primes[:3], createBoWMatrix(bow_bin, sentences_deux_primes[:3], tokens, None)) \n",
    "\n",
    "print(\"\\n---------------------------- Occ ----------------------------\\n\")\n",
    "createSimilarityMatrix(sentences_deux_primes[:3], createBoWMatrix(bow_occ, sentences_deux_primes[:3], tokens, None)) \n",
    "\n",
    "print(\"\\n---------------------------- N1 ----------------------------\\n\")\n",
    "\n",
    "createSimilarityMatrix(sentences_deux_primes[:3], createBoWMatrix(bow_occ, sentences_prime[:3], tokens, bow_N1)) # N1\n",
    "\n",
    "print(\"\\n---------------------------- N2 ----------------------------\\n\")\n",
    "\n",
    "createSimilarityMatrix(sentences_deux_primes[:3], createBoWMatrix(bow_occ, sentences_prime[:3], tokens, bow_N2)) # N2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d5516-ad50-4e0f-93e8-2e13d9c05851",
   "metadata": {},
   "source": [
    "# Brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc44d8f5-9711-44de-9204-7792b91627c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF_occ_total(token, documents):\n",
    "    occ_total = 0\n",
    "    tf = []\n",
    "    for token in tokens:\n",
    "        idf = 0\n",
    "        tf_token = []\n",
    "        for document in documents:\n",
    "            occ = document.count(token)\n",
    "            tf_token.append(occ)\n",
    "            if occ:\n",
    "                idf += 1\n",
    "        occ_total += sum(tf_token)\n",
    "        tf_token.append(idf)\n",
    "    \n",
    "    for token in range(len(tokens)-1):\n",
    "        \n",
    "    return ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "398ffc26-0f8d-4b4d-928a-1f05e69345b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hello  test  python  world  is  fun\n",
      "Doc_1      1     1       0      1   1    0\n",
      "Doc_2      1     0       0      1   0    0\n",
      "Doc_3      0     0       1      0   1    1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def bow_bin(documents, vocabulaire):\n",
    "    # Créer une liste pour stocker chaque vecteur binaire\n",
    "    bow_matrix = []\n",
    "\n",
    "    # Parcourir chaque document et créer le vecteur binaire\n",
    "    for document in documents:\n",
    "        tokens_document = document.split()\n",
    "        bow_bin = [1 if token in tokens_document else 0 for token in vocabulaire]\n",
    "        bow_matrix.append(bow_bin)\n",
    "\n",
    "    # Créer un DataFrame avec les documents en lignes et les tokens en colonnes\n",
    "    df = pd.DataFrame(bow_matrix, columns=vocabulaire, index=[f\"Doc_{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "documents = [\"hello world this is a test\", \"hello again world\", \"python is fun\"]\n",
    "vocabulaire = [\"hello\", \"test\", \"python\", \"world\", \"is\", \"fun\"]\n",
    "\n",
    "df = bow_bin(documents, vocabulaire)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4631b2da-e6d9-4a1f-93e5-4b0c55f690ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # pour l'affichage seulement\n",
    "\n",
    "def createBoWMatrix(function1, sentences, tokens, function2):\n",
    "\n",
    "    #matrix = []\n",
    "    #for sentence in sentences:\n",
    "    #    if function1 and function2:\n",
    "    #        matrix.append(function2(function1(sentence, tokens)))\n",
    "    #    elif function1:\n",
    "    #        matrix.append(function1(sentence, tokens))\n",
    "    #    else:\n",
    "    #        matrix.append(bow_occ(sentence, tokens)\n",
    "        \n",
    "    matrix = [function2(function1(sentence, tokens)) if function1 and function2\n",
    "            else function1(sentence, tokens) if function1\n",
    "            else bow_occ(sentence, tokens)\n",
    "            for sentence in sentences ]\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def createSimilarityMatrix(sentences, bow_matrix):\n",
    "    \n",
    "    euclidean_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "    manhattan_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "    cosinus_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                euclidean_matrix[i][j] = distance_euclidean(bow_matrix[i], bow_matrix[j])\n",
    "                manhattan_matrix[i][j] = distance_manhattan(bow_matrix[i], bow_matrix[j])\n",
    "                cosinus_matrix[i][j] = distance_cosinus(bow_matrix[i], bow_matrix[j])\n",
    "\n",
    "    print(\"\\nMatrice de similarité avec la distance euclidéene:\")\n",
    "    print(np.array(euclidean_matrix))\n",
    "    \n",
    "    print(\"\\nMatrice de similarité avec la distance manhattan:\")\n",
    "    print(np.array(manhattan_matrix))\n",
    "    \n",
    "    print(\"\\nMatrice de similarité avec la distance cosinus:\")\n",
    "    print(np.array(cosinus_matrix))\n",
    "                \n",
    "    #return euclidean_matrix, manhattan_matrix, cosinus_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
