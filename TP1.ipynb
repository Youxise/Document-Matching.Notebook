{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb57de3-5d31-4e19-bf1a-5854c9e49338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_corpus(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        return content\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def split_sentences(text):\n",
    "    #sentences = re.split(r'[.!?]', text)\n",
    "    return re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "\n",
    "def TP1(file_name):\n",
    "    # lecture de documents\n",
    "    text = read_corpus(file_name)\n",
    "    # phrases\n",
    "    sentences = split_sentences(text)\n",
    "    # phrases en minuscule & elimination des éléments vides\n",
    "    sentences_lowercase = [sentence.lower() for sentence in sentences if sentence]\n",
    "    # tokens\n",
    "    tokens_of_sentences = [remove_punctuation(sentence).split() for sentence in sentences_lowercase]\n",
    "    # vocabulaire\n",
    "    vocab = [token for sent_tokens in tokens_of_sentences for token in sent_tokens]\n",
    "    # elimination des doublons\n",
    "    vocab = list(set(vocab))\n",
    "\n",
    "    # affichage des résultats\n",
    "    print(f\"Le nombre de phrases est : {len(sentences_lowercase)}\")\n",
    "    print(f\"Le nombre de tokens est : {len(vocab)}\")\n",
    "    #print(f\"Les tokens sont : \\n{vocab}\")\n",
    "    #print(f\"Les phrases sont : \\n{sentences_lowercase}\")\n",
    "    \n",
    "    return sentences_lowercase, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1328c235-5dc4-4f6f-9ebd-09a4acc3cfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Corpus Obama ------------\n",
      "\n",
      "Le nombre de phrases est : 84\n",
      "Le nombre de tokens est : 658\n",
      "---------- Corpus Chirac ------------\n",
      "\n",
      "Le nombre de phrases est : 37\n",
      "Le nombre de tokens est : 293\n"
     ]
    }
   ],
   "source": [
    "Chirac = \"Corpus_Chirac.txt\"\n",
    "Obama = \"Corpus_Obama.txt\"\n",
    "\n",
    "print(\"\\n---------- Corpus Obama ------------\\n\")\n",
    "sentences, tokens = TP1(Obama)\n",
    "\n",
    "print(\"---------- Corpus Chirac ------------\\n\")\n",
    "sentences, tokens = TP1(Chirac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c588-db39-4b88-b937-d7f440a30cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
