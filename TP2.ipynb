{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdb413f-5feb-4c8b-b769-760a6a767108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Corpus Obama ------------\n",
      "\n",
      "Le nombre de phrases est : 84\n",
      "Le nombre de tokens est : 658\n",
      "---------- Corpus Chirac ------------\n",
      "\n",
      "Le nombre de phrases est : 37\n",
      "Le nombre de tokens est : 293\n"
     ]
    }
   ],
   "source": [
    "%run TP1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a73341-2e9e-4a42-850c-2bd7c0eef2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_bin(document, vocabulaire):\n",
    "    bow_bin = [1 if token in document.split() else 0 for token in vocabulaire]\n",
    "    return bow_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f959cadf-59f3-416d-baad-6f909438041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_occ(document, vocabulaire):\n",
    "    bow_occ = [document.split().count(token) for token in vocabulaire]\n",
    "    return bow_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6832a1dd-8c5d-422c-a866-48ff5008875d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_bin(sentences[0], tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71712283-37d6-4436-b020-cba7bc36c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_euclidean(vect1, vect2):\n",
    "    sum = 0\n",
    "    for i in range(len(vect1)):\n",
    "        sum += math.pow(vect1[i] - vect2[i], 2)\n",
    "    \n",
    "    return math.sqrt(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867768e5-4b58-468d-ada3-ad183bc0ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_manhattan(vect1, vect2):\n",
    "    sum = 0\n",
    "    for i in range(len(vect1)):\n",
    "        sum += abs(vect1[i] - vect2[i])\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4631b2da-e6d9-4a1f-93e5-4b0c55f690ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice BoW-bin :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Matrice BoW-occ:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Matrice de similarité avec BoW-bin et la distance euclidéene:\n",
      "[[0.         5.09901951 5.         ... 4.47213595 4.         4.        ]\n",
      " [5.09901951 0.         5.         ... 5.09901951 4.         4.        ]\n",
      " [5.         5.         0.         ... 5.         3.87298335 3.87298335]\n",
      " ...\n",
      " [4.47213595 5.09901951 5.         ... 0.         4.         4.        ]\n",
      " [4.         4.         3.87298335 ... 4.         0.         1.41421356]\n",
      " [4.         4.         3.87298335 ... 4.         1.41421356 0.        ]]\n",
      "\n",
      "Matrice de similarité avec BoW-bin et la distance manhattan:\n",
      "[[ 0 26 25 ... 20 16 16]\n",
      " [26  0 25 ... 26 16 16]\n",
      " [25 25  0 ... 25 15 15]\n",
      " ...\n",
      " [20 26 25 ...  0 16 16]\n",
      " [16 16 15 ... 16  0  2]\n",
      " [16 16 15 ... 16  2  0]]\n",
      "\n",
      "Matrice de similarité avec BoW-occ et la distance euclidéene:\n",
      "[[0.         5.91607978 5.09901951 ... 5.09901951 4.         4.        ]\n",
      " [5.91607978 0.         5.91607978 ... 6.70820393 5.56776436 5.56776436]\n",
      " [5.09901951 5.91607978 0.         ... 5.65685425 4.         4.        ]\n",
      " ...\n",
      " [5.09901951 6.70820393 5.65685425 ... 0.         4.69041576 4.69041576]\n",
      " [4.         5.56776436 4.         ... 4.69041576 0.         1.41421356]\n",
      " [4.         5.56776436 4.         ... 4.69041576 1.41421356 0.        ]]\n",
      "\n",
      "Matrice de similarité avec BoW-occ et la distance manhattan:\n",
      "[[ 0 29 26 ... 22 16 16]\n",
      " [29  0 29 ... 31 19 19]\n",
      " [26 29  0 ... 28 16 16]\n",
      " ...\n",
      " [22 31 28 ...  0 18 18]\n",
      " [16 19 16 ... 18  0  2]\n",
      " [16 19 16 ... 18  2  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # pour l'affichage seulement\n",
    "import math\n",
    "\n",
    "#sentences = [\n",
    "#    \"the cat sat on the mat\",\n",
    "#    \"the dog sat on the log\",\n",
    "#    \"the cat and dog are friends\"\n",
    "#]\n",
    "#tokens = list(set(\" \".join(sentences).split()))\n",
    "\n",
    "# création des matrices BoW\n",
    "bow_bin_matrix = [bow_bin(sentence, tokens) for sentence in sentences]\n",
    "bow_occ_matrix = [bow_occ(sentence, tokens) for sentence in sentences]\n",
    "\n",
    "# affichage\n",
    "print(\"Matrice BoW-bin :\")\n",
    "print(np.array(bow_bin_matrix))\n",
    "\n",
    "\n",
    "print(\"\\nMatrice BoW-occ:\")\n",
    "print(np.array(bow_occ_matrix))\n",
    "\n",
    "\n",
    "# initialisation des matrices de distances\n",
    "euclidean_occ_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "manhattan_occ_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "euclidean_bin_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "manhattan_bin_matrix = [[0] * len(sentences) for _ in range(len(sentences))]\n",
    "\n",
    "# calcul des distances et remplissage des matrices \n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            euclidean_occ_matrix[i][j] = distance_euclidean(bow_occ_matrix[i], bow_occ_matrix[j])\n",
    "            manhattan_occ_matrix[i][j] = distance_manhattan(bow_occ_matrix[i], bow_occ_matrix[j])\n",
    "            euclidean_bin_matrix[i][j] = distance_euclidean(bow_bin_matrix[i], bow_bin_matrix[j])\n",
    "            manhattan_bin_matrix[i][j] = distance_manhattan(bow_bin_matrix[i], bow_bin_matrix[j])\n",
    "\n",
    "# affichage\n",
    "print(\"\\nMatrice de similarité avec BoW-bin et la distance euclidéene:\")\n",
    "print(np.array(euclidean_bin_matrix))\n",
    "\n",
    "print(\"\\nMatrice de similarité avec BoW-bin et la distance manhattan:\")\n",
    "print(np.array(manhattan_bin_matrix))\n",
    "\n",
    "\n",
    "print(\"\\nMatrice de similarité avec BoW-occ et la distance euclidéene:\")\n",
    "print(np.array(euclidean_occ_matrix))\n",
    "\n",
    "\n",
    "print(\"\\nMatrice de similarité avec BoW-occ et la distance manhattan:\")\n",
    "print(np.array(manhattan_occ_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7875fda9-794b-4112-a2cc-a242aba498ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_plus_proches_documents(doc_query, k, sentences, similarity_matrix, tokens):\n",
    "    # si le document est parmis la liste\n",
    "    if doc_query in sentences:\n",
    "        doc_idx = sentences.index(doc_query) # recuperer l'index\n",
    "        doc_vector = similarity_matrix[doc_idx]\n",
    "        k_documents = sorted(range(len(doc_vector)), key=lambda i: doc_vector[i])[:k]\n",
    "    # nouveau document\n",
    "    else:\n",
    "        doc_query_bow_occ = bow_occ(doc_query, tokens) # représantation BoW\n",
    "        doc_query_sim = []\n",
    "        for i in range(len(sentences)): # calcul des distances\n",
    "            doc_query_sim.append(distance_euclidean(bow_occ_matrix[i], doc_query_bow_occ))\n",
    "        print(doc_query_sim)\n",
    "        # recuperation des indexes des plus proches\n",
    "        k_documents = sorted(range(len(doc_query_sim)), key=lambda i: doc_query_sim[i])[:k]\n",
    "        \n",
    "    return [sentences[i] for i in k_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53399399-6fad-4f5e-a6b5-d52af8321ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 5.5677643628300215, 4.242640687119285, 5.385164807134504, 3.4641016151377544, 5.830951894845301, 6.164414002968976, 5.385164807134504, 4.123105625617661, 4.58257569495584, 3.3166247903554, 3.7416573867739413, 5.0990195135927845, 4.0, 4.0, 3.1622776601683795, 6.082762530298219, 4.69041575982343, 3.605551275463989, 5.291502622129181, 4.47213595499958, 2.23606797749979, 3.0, 3.4641016151377544, 7.0710678118654755, 6.48074069840786, 6.6332495807108, 6.4031242374328485, 2.449489742783178, 4.0, 7.615773105863909, 4.795831523312719, 5.0, 4.898979485566356, 4.47213595499958, 2.0, 1.4142135623730951]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vive la france',\n",
       " 'vive la république',\n",
       " \"la fraternité, c'est sauvegarder les retraites\",\n",
       " \"cette exigence s'impose à chacun d'entre nous\",\n",
       " \"c'est aider les familles à jouer pleinement leur rôle\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_query = \"france\"\n",
    "k = 5\n",
    "\n",
    "K_plus_proches_documents(doc_query, k, sentences, euclidean_occ_matrix, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b693f-bcb0-495e-bcfe-fe95f2573291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
